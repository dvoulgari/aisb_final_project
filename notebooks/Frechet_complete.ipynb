{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d599e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio import PDB\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20838fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute the Euclidean distance between two points ---\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"\n",
    "    The euclidean distance between two 3D points.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt((x[0][0]-y[0][0])**2 + (x[0][1]-y[0][1])**2+(x[0][2]-y[0][2])**2)\n",
    "\n",
    "# --- PDB Extraction Function ---\n",
    "def extract_ca_coordinates(pdb_file):\n",
    "    \"\"\"\n",
    "    Loads a PDB file and extracts C-alpha coordinates for each standard amino acid,\n",
    "    returning them as a list of NumPy arrays, where each array is (1, 3) for a single residue.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"prot\", pdb_file)\n",
    "    \n",
    "    coords_per_residue = [] \n",
    "    \n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if PDB.is_aa(residue, standard=True) and residue.has_id('CA'):\n",
    "                    coords_per_residue.append(np.array([residue['CA'].coord]))\n",
    "    \n",
    "    return coords_per_residue\n",
    "\n",
    "\n",
    "# --- calculate_rmsd_after_superposition function ---\n",
    "def calculate_rmsd_after_superposition(coords1, coords2):\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Square Deviation (RMSD) between two sets of 3D coordinates\n",
    "    after optimally superposing coords2 onto coords1 using the Kabsch algorithm (via scipy).\n",
    "\n",
    "    Args:\n",
    "        coords1 (np.ndarray): N x 3 array of 3D coordinates (reference).\n",
    "        coords2 (np.ndarray): M x 3 array of 3D coordinates (to be superposed).\n",
    "\n",
    "    Returns:\n",
    "        float: The minimal RMSD between the two sets of coordinates.\n",
    "    \"\"\"\n",
    "    # Robustness checks for empty arrays\n",
    "    if coords1.shape[0] == 0 and coords2.shape[0] == 0:\n",
    "        return 0.0 # Both empty, perfectly \"aligned\" (no cost)\n",
    "    elif coords1.shape[0] == 0 or coords2.shape[0] == 0:\n",
    "        # One is empty, the other is not. This should incur a high cost.\n",
    "        return 1000.0 # A high penalty, indicating a fundamental mismatch\n",
    "    \n",
    "    # Handle single-point comparison directly (avoids R.align_vectors issues for N=1)\n",
    "    if coords1.shape[0] == 1 and coords2.shape[0] == 1:\n",
    "        return np.linalg.norm(coords1[0] - coords2[0]) # Euclidean distance for 1 point is its RMSD\n",
    "\n",
    "    # Standard sanity check for 3D coordinates\n",
    "    if coords1.shape[1] != 3 or coords2.shape[1] != 3:\n",
    "        raise ValueError(\"Input coordinate arrays must be (N, 3) or (M, 3).\")\n",
    "\n",
    "    # Center the coordinates\n",
    "    centroid1 = np.mean(coords1, axis=0)\n",
    "    centroid2 = np.mean(coords2, axis=0)\n",
    "    centered_coords1 = coords1 - centroid1\n",
    "    centered_coords2 = coords2 - centroid2\n",
    "\n",
    "    # --- Check for degenerate (all points identical / zero length after centering) inputs ---\n",
    "    # If the sum of squared magnitudes of the centered vectors is effectively zero,\n",
    "    # it means all points are identical, and alignment is trivial (RMSD is 0).\n",
    "    is_coords1_degenerate = np.isclose(np.sum(centered_coords1**2), 0.0)\n",
    "    is_coords2_degenerate = np.isclose(np.sum(centered_coords2**2), 0.0)\n",
    "\n",
    "    if is_coords1_degenerate and is_coords2_degenerate:\n",
    "        return 0.0 # Both sets of points are effectively identical (or collapsed to a single point)\n",
    "    elif is_coords1_degenerate or is_coords2_degenerate:\n",
    "        # One set is degenerate (e.g., all its atoms are at the same coordinate),\n",
    "        # while the other is not. This is a significant structural mismatch.\n",
    "        return 1000.0 # High penalty\n",
    "\n",
    "    # Find the optimal rotation (will only be called if N > 1 AND not degenerate)\n",
    "    rotation, rmsd = R.align_vectors(centered_coords2, centered_coords1)\n",
    "\n",
    "    return rmsd\n",
    "\n",
    "\n",
    "# --- dtw_with_rmsd_cost function ---\n",
    "def frechet_with_rmsd_cost(seq1_coords, seq2_coords):\n",
    "    \"\"\"\n",
    "    Performs Frechet on two sequences of 3D backbone coordinates,\n",
    "    using RMSD as the local cost metric between corresponding residues.\n",
    "\n",
    "    Args:\n",
    "        seq1_coords (list of np.ndarray): List where each element is a (1, 3) or (N_atoms, 3)\n",
    "                                          numpy array representing the coordinates for one residue/segment.\n",
    "                                          For simple C-alpha, it's (1, 3).\n",
    "        seq2_coords (list of np.ndarray): Similar list for the second sequence.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (dtw_cost, warping_path)\n",
    "            dtw_cost (float): The total accumulated cost of the optimal warping path.\n",
    "            warping_path (list): A list of (index_seq1, index_seq2) tuples representing\n",
    "                                 the optimal alignment path.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(seq1_coords)\n",
    "    m = len(seq2_coords)\n",
    "\n",
    "    # Initialize the cost matrix\n",
    "    D = np.full((n, m), np.inf)\n",
    "\n",
    "    # Fill D[0][0]\n",
    "    D[0, 0] = calculate_rmsd_after_superposition(seq1_coords[0].reshape(-1, 3), seq2_coords[0].reshape(-1, 3))\n",
    "\n",
    "    # Fill first column\n",
    "    for i in range(1, n):\n",
    "        cost = calculate_rmsd_after_superposition(seq1_coords[i].reshape(-1, 3), seq2_coords[0].reshape(-1, 3))\n",
    "        D[i, 0] = max(D[i - 1, 0], cost)\n",
    "\n",
    "    # Fill first row\n",
    "    for j in range(1, m):\n",
    "        cost = calculate_rmsd_after_superposition(seq1_coords[0].reshape(-1, 3), seq2_coords[j].reshape(-1, 3))\n",
    "        D[0, j] = max(D[0, j - 1], cost)\n",
    "\n",
    "    # Fill the rest of the matrix\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, m):\n",
    "            cost = calculate_rmsd_after_superposition(seq1_coords[i].reshape(-1, 3), seq2_coords[j].reshape(-1, 3))\n",
    "            min_prev = min(D[i - 1, j], D[i - 1, j - 1], D[i, j - 1])\n",
    "            D[i, j] = max(cost, min_prev)\n",
    "\n",
    "    # Optional: Traceback to get the warping path\n",
    "    path = []\n",
    "    i, j = n - 1, m - 1\n",
    "    path.append((i, j))\n",
    "    while i > 0 or j > 0:\n",
    "        candidates = []\n",
    "        if i > 0 and j > 0:\n",
    "            candidates.append((D[i - 1, j - 1], i - 1, j - 1))\n",
    "        if i > 0:\n",
    "            candidates.append((D[i - 1, j], i - 1, j))\n",
    "        if j > 0:\n",
    "            candidates.append((D[i, j - 1], i, j - 1))\n",
    "        if candidates:\n",
    "            _, i, j = min(candidates)\n",
    "            path.append((i, j))\n",
    "\n",
    "    path.reverse()\n",
    "\n",
    "\n",
    "    total_cost = D[n-1, m-1]\n",
    "    length_of_warping_path = len(path)\n",
    "\n",
    "    if length_of_warping_path > 0:\n",
    "        normalized_frechet_cost = total_cost / length_of_warping_path\n",
    "    else:\n",
    "        # This case should ideally not happen if n > 0 or m > 0 due to path construction,\n",
    "        # but as a safeguard\n",
    "        normalized_frechet_cost = np.inf if (n > 0 or m > 0) else 0.0\n",
    "\n",
    "    return normalized_frechet_cost, path\n",
    "\n",
    "\n",
    "\n",
    "def frechet_with_euclidean_cost(seq1_coords, seq2_coords):\n",
    "    \"\"\"\n",
    "    Performs Frechet on two sequences of 3D backbone coordinates,\n",
    "    using Euclidean distance as the local cost metric between corresponding residues.\n",
    "\n",
    "    Args:\n",
    "        seq1_coords (list of np.ndarray): List where each element is a (1, 3) or (N_atoms, 3)\n",
    "                                          numpy array representing the coordinates for one residue/segment.\n",
    "                                          For simple C-alpha, it's (1, 3).\n",
    "        seq2_coords (list of np.ndarray): Similar list for the second sequence.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (dtw_cost, warping_path)\n",
    "            dtw_cost (float): The total accumulated cost of the optimal warping path.\n",
    "            warping_path (list): A list of (index_seq1, index_seq2) tuples representing\n",
    "                                 the optimal alignment path.\n",
    "    \"\"\"\n",
    "    n = len(seq1_coords)\n",
    "    m = len(seq2_coords)\n",
    "\n",
    "    # Initialize the cost matrix\n",
    "    D = np.full((n, m), np.inf)\n",
    "\n",
    "    # Fill D[0][0]\n",
    "    D[0, 0] = euclidean_distance(seq1_coords[0].reshape(-1, 3), seq2_coords[0].reshape(-1, 3))\n",
    "\n",
    "    # Fill first column\n",
    "    for i in range(1, n):\n",
    "        cost = euclidean_distance(seq1_coords[i].reshape(-1, 3), seq2_coords[0].reshape(-1, 3))\n",
    "        D[i, 0] = max(D[i - 1, 0], cost)\n",
    "\n",
    "    # Fill first row\n",
    "    for j in range(1, m):\n",
    "        cost = euclidean_distance(seq1_coords[0].reshape(-1, 3), seq2_coords[j].reshape(-1, 3))\n",
    "        D[0, j] = max(D[0, j - 1], cost)\n",
    "\n",
    "    # Fill the rest of the matrix\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, m):\n",
    "            cost = euclidean_distance(seq1_coords[i].reshape(-1, 3), seq2_coords[j].reshape(-1, 3))\n",
    "            min_prev = min(D[i - 1, j], D[i - 1, j - 1], D[i, j - 1])\n",
    "            D[i, j] = max(cost, min_prev)\n",
    "\n",
    "    # Optional: Traceback to get the warping path\n",
    "    path = []\n",
    "    i, j = n - 1, m - 1\n",
    "    path.append((i, j))\n",
    "    while i > 0 or j > 0:\n",
    "        candidates = []\n",
    "        if i > 0 and j > 0:\n",
    "            candidates.append((D[i - 1, j - 1], i - 1, j - 1))\n",
    "        if i > 0:\n",
    "            candidates.append((D[i - 1, j], i - 1, j))\n",
    "        if j > 0:\n",
    "            candidates.append((D[i, j - 1], i, j - 1))\n",
    "        if candidates:\n",
    "            _, i, j = min(candidates)\n",
    "            path.append((i, j))\n",
    "\n",
    "    path.reverse()\n",
    "\n",
    "\n",
    "    total_cost = D[n-1, m-1]\n",
    "    length_of_warping_path = len(path)\n",
    "\n",
    "    if length_of_warping_path > 0:\n",
    "        normalized_frechet_cost = total_cost / length_of_warping_path\n",
    "    else:\n",
    "        # This case should ideally not happen if n > 0 or m > 0 due to path construction,\n",
    "        # but as a safeguard\n",
    "        normalized_frechet_cost = np.inf if (n > 0 or m > 0) else 0.0\n",
    "\n",
    "    return normalized_frechet_cost, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95417d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Usage ---\n",
    "\n",
    "# # Load PDB and extract coordinates\n",
    "# seq1_coords = extract_ca_coordinates('../data/1tim.pdb')\n",
    "# seq2_coords = extract_ca_coordinates('../data/7tim.pdb')\n",
    "\n",
    "# print(f\"Sequence 1 has {len(seq1_coords)} residues.\")\n",
    "# print(f\"Sequence 2 has {len(seq2_coords)} residues.\")\n",
    "\n",
    "# if seq1_coords and seq2_coords: # Proceed only if both sequences have data\n",
    "#     total_cost_RMSD, path_RMSD = frechet_with_rmsd_cost(seq1_coords, seq2_coords)\n",
    "\n",
    "#     print(f\"\\nTotal Frechet Cost RMSD: {total_cost_RMSD:.4f} Angstroms\")\n",
    "#     # --- Code to calculate Normalized DTW Distance ---\n",
    "#     length_of_warping_path = len(path_RMSD)\n",
    "#     if length_of_warping_path > 0:\n",
    "#         normalized_frechet_distance = total_cost_RMSD / length_of_warping_path\n",
    "#         print(f\"Normalized Frechet Distance (by Length Path): {normalized_frechet_distance:.4f} Angstroms\")\n",
    "#     else:\n",
    "#         print(\"Warning: Path has zero length, cannot normalize Frechet distance.\")\n",
    "\n",
    "#     # total_cost_euclidean, path_euclidean= frechet_with_euclidean_cost(seq1_coords, seq2_coords)\n",
    "\n",
    "#     # print(f\"\\nTotal Frechet Cost Euclidean: {total_cost_euclidean:.4f} Angstroms\")\n",
    "#     # # --- Code to calculate Normalized DTW Distance ---\n",
    "#     # length_of_warping_path = len(path_euclidean)\n",
    "#     # if length_of_warping_path > 0:\n",
    "#     #     normalized_frechet_distance = total_cost_RMSD / length_of_warping_path\n",
    "#     #     print(f\"Normalized Frechet Distance (by Length Path): {normalized_frechet_distance:.4f} Angstroms\")\n",
    "#     # else:\n",
    "#     #     print(\"Warning: Path has zero length, cannot normalize Frechet distance.\")\n",
    "\n",
    "#     # print(\"\\nOptimal Walking Path:\")\n",
    "#     # for i, (idx1, idx2) in enumerate(path):\n",
    "#     #     print(f\"  Path Step {i+1}: seq1_residue[{idx1}] <-> seq2_residue[{idx2}]\")\n",
    "#     # if len(path) > 100:\n",
    "#     #     print(\"  ...\")\n",
    "# else:\n",
    "#     print(\"\\nError: One or both PDB files resulted in empty C-alpha coordinate lists.\")\n",
    "#     print(\"Please check the PDB files and the `extract_ca_coordinates` function's filtering conditions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673585da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDB files in '../antibodies/sanity'.\n",
      "Step 1/2: Extracting C-alpha coordinates from all PDB files (sequential)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Coordinates: 100%|██████████| 2/2 [00:00<00:00, 30.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted C-alpha coordinates for 2 valid PDBs.\n",
      "Step 2/2: Starting pairwise Frechet comparisons (1 in total) using multiprocessing...\n",
      "Using 12 CPU cores for parallel processing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frechet Comparisons:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# --- Worker function for parallel processing ---\n",
    "# This function must be defined at the top level (not inside if __name__ == \"__main__\":) so it can be pickled and sent to other processes.\n",
    "def _compare_pair(args):\n",
    "    pdb_id1, pdb_id2, coords1, coords2 = args\n",
    "    try:\n",
    "        frechet_distance, _ = frechet_with_rmsd_cost(coords1, coords2)\n",
    "        return {'PDB1': pdb_id1, 'PDB2': pdb_id2, 'Frechet_Distance_Normalized': frechet_distance}\n",
    "    except Exception as e:\n",
    "        # Handle potential errors during comparison, return NaN or a high penalty\n",
    "        print(f\"Error comparing {pdb_id1} and {pdb_id2}: {e}\")\n",
    "        return {'PDB1': pdb_id1, 'PDB2': pdb_id2, 'Frechet_Distance_Normalized': np.nan}\n",
    "    \n",
    "# --- Main Automation Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # CHANGE THAT\n",
    "    pdb_folder_path = \"../antibodies/antibodies\" # <-------- CHANGE THAT\n",
    "\n",
    "    if not os.path.exists(pdb_folder_path):\n",
    "        print(f\"Error: PDB folder not found at '{pdb_folder_path}'. Please check the path.\")\n",
    "        exit()\n",
    "\n",
    "    # Get list of all PDB files\n",
    "    pdb_files = [f for f in os.listdir(pdb_folder_path) if f.endswith('.pdb')]\n",
    "    pdb_files.sort() # Ensure consistent order\n",
    "\n",
    "    print(f\"Found {len(pdb_files)} PDB files in '{pdb_folder_path}'.\")\n",
    "    if len(pdb_files) < 2:\n",
    "        print(\"Need at least two PDB files for comparison. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Cache extracted coordinates to avoid re-parsing PDBs for each comparison\n",
    "    # This step will still run sequentially first.\n",
    "    parsed_pdb_coords = {}\n",
    "    print(\"Step 1/2: Extracting C-alpha coordinates from all PDB files (sequential)...\")\n",
    "    for pdb_file_name in tqdm(pdb_files, desc=\"Extracting Coordinates\"):\n",
    "        pdb_full_path = os.path.join(pdb_folder_path, pdb_file_name)\n",
    "        pdb_id = os.path.splitext(pdb_file_name)[0]\n",
    "        coords = extract_ca_coordinates(pdb_full_path)\n",
    "        if len(coords) > 0:\n",
    "            parsed_pdb_coords[pdb_id] = coords\n",
    "        else:\n",
    "            print(f\"Skipping {pdb_id} due to empty or problematic C-alpha extraction.\")\n",
    "\n",
    "    valid_pdb_ids = list(parsed_pdb_coords.keys())\n",
    "    print(f\"Successfully extracted C-alpha coordinates for {len(valid_pdb_ids)} valid PDBs.\")\n",
    "\n",
    "    # Prepare tasks for the multiprocessing pool\n",
    "    tasks = []\n",
    "    for i in range(len(valid_pdb_ids)):\n",
    "        pdb_id1 = valid_pdb_ids[i]\n",
    "        coords1 = parsed_pdb_coords[pdb_id1]\n",
    "        for j in range(i + 1, len(valid_pdb_ids)): # Compare each unique pair\n",
    "            pdb_id2 = valid_pdb_ids[j]\n",
    "            coords2 = parsed_pdb_coords[pdb_id2]\n",
    "            tasks.append((pdb_id1, pdb_id2, coords1, coords2)) # Store arguments as a tuple\n",
    "\n",
    "    total_comparisons = len(tasks)\n",
    "    print(f\"Step 2/2: Starting pairwise Frechet comparisons ({total_comparisons} in total) using multiprocessing...\")\n",
    "\n",
    "    # Determine the number of CPU cores to use\n",
    "    num_processes = os.cpu_count()\n",
    "    if num_processes is None: # Fallback for systems that don't report CPU count\n",
    "        num_processes = 4 # Default to 4 if not detected\n",
    "    print(f\"Using {num_processes} CPU cores for parallel processing.\")\n",
    "\n",
    "    comparison_results = []\n",
    "    # Use multiprocessing Pool to distribute tasks\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        # imap_unordered is good for progress bars as it yields results as they complete\n",
    "        for result in tqdm(pool.imap_unordered(_compare_pair, tasks), total=total_comparisons, desc=\"Frechet Comparisons\"):\n",
    "            if result is not None: # Collect results, skipping any None from errors\n",
    "                comparison_results.append(result)\n",
    "\n",
    "    # Store results in a Pandas DataFrame\n",
    "    frechet_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_csv_path = \"pairwise_frechet_distances_parallel.csv\"\n",
    "    frechet_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\nAll pairwise Frechet distances saved to '{output_csv_path}'\")\n",
    "\n",
    "    # Display a sample of the results\n",
    "    print(\"\\nSample of Pairwise Frechet Distances:\")\n",
    "    print(frechet_df.head())\n",
    "\n",
    "    # Create and save the square distance matrix\n",
    "    pdb_ids_list = sorted(list(parsed_pdb_coords.keys())) # Ensure consistent order\n",
    "    distance_matrix = np.full((len(pdb_ids_list), len(pdb_ids_list)), np.nan) # Use nan for self-comparison/uncomputed\n",
    "\n",
    "    # Create mapping from PDB ID to index\n",
    "    pdb_id_to_idx = {pdb_id: i for i, pdb_id in enumerate(pdb_ids_list)}\n",
    "\n",
    "    # Fill diagonal with 0.0 (distance to self)\n",
    "    np.fill_diagonal(distance_matrix, 0.0)\n",
    "\n",
    "    for _, row in frechet_df.iterrows():\n",
    "        idx1 = pdb_id_to_idx[row['PDB1']]\n",
    "        idx2 = pdb_id_to_idx[row['PDB2']]\n",
    "        distance_matrix[idx1, idx2] = row['Frechet_Distance_Normalized']\n",
    "        distance_matrix[idx2, idx1] = row['Frechet_Distance_Normalized'] # Symmetric matrix\n",
    "\n",
    "    # Save the distance matrix\n",
    "    np.save(\"frechet_distance_matrix_parallel.npy\", distance_matrix)\n",
    "    print(f\"Freceht distance matrix (NumPy array) saved to 'frechet_distance_matrix_parallel.npy'\")\n",
    "    \n",
    "    # # Save as CSV for easier viewing (optional, can be very large)\n",
    "    # distance_matrix_df = pd.DataFrame(distance_matrix, index=pdb_ids_list, columns=pdb_ids_list)\n",
    "    # distance_matrix_df.to_csv(\"frechet_distance_matrix_parallel.csv\")\n",
    "    # print(f\"DTW distance matrix (CSV) saved to 'frechet_distance_matrix_parallel.csv'\")\n",
    "\n",
    "    print(\"\\nParallel processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
